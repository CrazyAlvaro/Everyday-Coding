{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "###########################################\n",
    "# Configuation\n",
    "###########################################\n",
    "\n",
    "# Assume laneId provided in preceeding data processor\n",
    "lane_id_col = 'lane_id'\n",
    "columns_tracks = ['frame', 'trackId', 'xCenter', 'yCenter', 'length', 'width',\n",
    "                'xVelocity', 'yVelocity', 'xAcceleration', 'yAcceleration',\n",
    "                'frontSightDistance', 'backSightDistance', 'dhw', 'thw', 'ttc',\n",
    "                'precedingXVelocity', 'precedingId', 'followingId', 'leftPrecedingId',\n",
    "                'leftAlongsideId', 'leftFollowingId', 'rightPrecedingId',\n",
    "                'rightAlongsideId', 'rightFollowingId', 'laneId', 'angle',\n",
    "                'orientation', 'yaw_rate ', 'ego_offset']\n",
    "columns_tracks_meta = ['trackId', 'length', 'width', 'initialFrame', 'finalFrame', 'numFrames',\n",
    "       'class', 'drivingDirection', 'traveledDistance', 'minXVelocity',\n",
    "       'maxXVelocity', 'meanXVelocity', 'minDHW', 'minTHW', 'minTTC',\n",
    "       'numLaneChanges'] \n",
    "columns_recording_meta = ['recordingId', 'frameRate', 'locationId', 'speedLimit', 'month',\n",
    "       'weekDay', 'startTime', 'duration', 'totalDrivenDistance',\n",
    "       'totalDrivenTime', 'numVehicles', 'numCars', 'numTrucks', 'numBuses',\n",
    "       'laneMarkings', 'scale']\n",
    "\n",
    "# def parse_timestamp(timestamp_str):\n",
    "#     \"\"\"\n",
    "#     自定义解析函数，处理纳秒数据\n",
    "#     \"\"\"\n",
    "\n",
    "#     # 转换为秒\n",
    "#     seconds_timestamp = np.int64(timestamp_str) / 10**9\n",
    "\n",
    "#     # 转换为datetime对象\n",
    "#     dt = datetime.datetime.fromtimestamp(seconds_timestamp)\n",
    "\n",
    "#     # 格式为年-月-日 时:分:秒.纳秒\n",
    "#     return pd.to_datetime(dt, format='%Y-%m-%d %H:%M:%S.%f')  \n",
    "\n",
    "\n",
    "# 读取多个CSV文件\n",
    "# df_ego = pd.read_csv(\"ego.csv\", index_col='ts', parse_dates=['ts'], date_format=parse_timestamp)\n",
    "# df_obj = pd.read_csv(\"obj.csv\", index_col='ts', parse_dates=['ts'], date_format=parse_timestamp)\n",
    "df_ego = pd.read_csv(\"ego.csv\")\n",
    "df_obj = pd.read_csv(\"obj.csv\")\n",
    "# ... 其他传感器文件\n",
    "\n",
    "# df_ego 加入 obj_id 字段 取 1\n",
    "ego_obj_id = 1\n",
    "df_ego['obj_id'] = ego_obj_id \n",
    "\n",
    "# NOTE: Assume we have laneId \n",
    "# add column 'laneId' to both ego and obj if needed\n",
    "if lane_id_col not in df_ego.columns:\n",
    "    df_ego[lane_id_col] = 0\n",
    "\n",
    "if lane_id_col not in df_obj.columns:\n",
    "    df_obj[lane_id_col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(df_ego['obj_id'].isnull().any())\n",
    "print(df_obj['obj_id'].isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " [NoUse]Check obj_id of merge dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing nano seconds timestamp\n",
    "\n",
    "# 合并DataFrame\n",
    "# df_merged = pd.concat([df_ego, df_obj], axis=0, ignore_index=True)\n",
    "\n",
    "# 处理缺失值（例如填充为0）\n",
    "# df_merged.fillna(0, inplace=True)\n",
    "\n",
    "# check obj_id\n",
    "# print(df_merged['obj_id'].head)\n",
    "# print(f\"if any obj_id is NaN:{df_merged['obj_id'].isnull().any()}\\n\")\n",
    "# print(f\"Number of rows : {len(df_merged)}\")\n",
    "# print(f\"Number of unique obj_id: {df_merged['obj_id'].nunique()}\")\n",
    "\n",
    "# print(f\"Number of unique ts: {df_merged['ts'].nunique()}\")\n",
    "\n",
    "# print(f\"Number of unique ts in obj: {df_obj['ts'].nunique()}\")\n",
    "# print(f\"Number of unique ts in ego: {df_ego['ts'].nunique()}\")\n",
    "\n",
    "# 查看合并后的DataFrame\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Interpolation in ego"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data timestamp arrange \n",
    "\n",
    "add obj's unique ts to ego, then interpolate new ts in ego from existing ts\n",
    "\n",
    "Since we need ego state in all ts of obj, we need to estimate the state data of ego in all obj ts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique ts in obj: 299\n",
      "unique ts in ego: 998\n",
      "unique ts in obj_not_ego: 298\n"
     ]
    }
   ],
   "source": [
    "ts_obj = df_obj['ts'].unique()\n",
    "ts_ego = df_ego['ts'].unique()\n",
    "ts_obj_not_ego = [ts for ts in ts_obj if ts not in ts_ego]\n",
    "\n",
    "print(f\"unique ts in obj: {len(ts_obj)}\")\n",
    "print(f\"unique ts in ego: {len(ts_ego)}\")\n",
    "print(f\"unique ts in obj_not_ego: {len(ts_obj_not_ego)}\")\n",
    "\n",
    "# augment ego with ts in obj\n",
    "df_obj_ts = pd.DataFrame(np.array(ts_obj_not_ego), columns=['ts'])\n",
    "\n",
    "# concat with df_ego\n",
    "df_ego_augment = pd.concat([df_ego, df_obj_ts], axis=0, ignore_index=True)\n",
    "\n",
    "# sort by ts and reindex\n",
    "df_ego_augment.sort_values(by='ts', inplace=True)\n",
    "df_ego_augment.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# update obj_id of new rows\n",
    "df_ego_augment['obj_id'] = ego_obj_id \n",
    "\n",
    "# store middle data to csv\n",
    "# df_ego_augment.to_csv('ego_augment.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation of ego in obj ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation for x, y values\n",
    "\n",
    "# 1 create new index with ts\n",
    "df_ego_augment['timestamp'] = pd.to_datetime(df_ego_augment['ts'])\n",
    "df_ego_augment.set_index('timestamp', inplace=True)\n",
    "\n",
    "df_ego_augment.to_csv('ego_augment.csv', index=False)\n",
    "# df_ego_augment.to_csv('ego_augment.csv', index=True)\n",
    "\n",
    "# 2 interpolate columns with time method by index\n",
    "interpolate_columns = ['x','y','z','h','spd_mps', 'spd_kph', 'acc_lgt_mpss', 'acc_lat_mpss']\n",
    "\n",
    "# create a new dataframe but share underline value for memory optimization\n",
    "df_ego_interpolated = df_ego_augment.copy(deep=False)\n",
    "\n",
    "for col in interpolate_columns:\n",
    "    df_ego_interpolated[col] = df_ego_interpolated[col].interpolate(method='time')\n",
    "\n",
    "df_ego_interpolated.to_csv('ego_augment_interpolated.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat df_ego_interpolated and df_obj to df_obj_augment\n",
    "here df_obj_augment has all obj_id (obj and ego), with each obj's ts has ego position interpolated from previous processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# concat df_ego_augment to df_obj for late obj axis transform to ground axis\n",
    "df_obj_augment = pd.concat([df_obj, df_ego_interpolated], axis=0)\n",
    "\n",
    "# sort all vehicles by ts-timestamp value\n",
    "df_obj_augment.sort_values(by='ts', inplace=True)\n",
    "\n",
    "# sort dataframe for reviewing\n",
    "df_obj_augment.to_csv('obj_augment.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obj Track Computation from ego data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set ego vel_lgt_mps, vel_lat_mps\n",
    "df_obj_augment.loc[df_obj_augment['obj_id'] == ego_obj_id, 'vel_lgt_mps'] = df_obj_augment['spd_mps']\n",
    "df_obj_augment.loc[df_obj_augment['obj_id'] == ego_obj_id, 'vel_lat_mps'] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traverse obj_augment to axis transformation\n",
    "\n",
    "update obj's x and y position according to ego's x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_columns_exist_robust(df, column_names):\n",
    "    \"\"\"\n",
    "    Robust version of ensure_columns_exist, handling potential errors.\n",
    "\n",
    "    Args:\n",
    "        df: The Pandas DataFrame.\n",
    "        column_names: A list of strings representing column names.\n",
    "\n",
    "    Returns:\n",
    "        The DataFrame, potentially with new columns added, or None if an error occurs.\n",
    "        Prints messages indicating actions taken or errors.\n",
    "    \"\"\"\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print(\"Error: Input 'df' must be a Pandas DataFrame.\")\n",
    "        return None\n",
    "\n",
    "    if not column_names:  # Handle empty list of column names\n",
    "        print(\"No column names provided. Nothing to do.\")\n",
    "        return df\n",
    "\n",
    "    if not all(isinstance(col, str) for col in column_names):\n",
    "        print(\"Error: All elements in 'column_names' must be strings.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        for col_name in column_names:\n",
    "            if col_name not in df.columns:\n",
    "                df[col_name] = pd.NA\n",
    "                print(f\"Column '{col_name}' created.\")\n",
    "            else:\n",
    "                print(f\"Column '{col_name}' already exists.\")\n",
    "        return df\n",
    "    except Exception as e: # Catch potential exceptions during column creation\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_vector(x1, y1, angle_radians):\n",
    "    \"\"\"\n",
    "    Rotates a vector from one coordinate system (RF1) to another (RF2).\n",
    "\n",
    "    Args:\n",
    "        x1: The x-component of the vector in RF1.\n",
    "        y1: The y-component of the vector in RF1.\n",
    "        angle_radians: The angle of rotation from RF1 to RF2, measured counter-clockwise.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the x and y components of the rotated vector in RF2 (x2, y2).\n",
    "        Returns None if input is invalid.\n",
    "    \"\"\"\n",
    "    if not isinstance(x1, (int, float)) or not isinstance(y1, (int, float)) or not isinstance(angle_radians, (int, float)):\n",
    "      print(\"x1, y1 and angle must be numbers\")\n",
    "      return None\n",
    "\n",
    "    x2 = x1 * math.cos(angle_radians) - y1 * math.sin(angle_radians)\n",
    "    y2 = x1 * math.sin(angle_radians) + y1 * math.cos(angle_radians)\n",
    "    return (x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tracks(df):\n",
    "    \"\"\"\n",
    "    Assigns unique track IDs and frame numbers to objects in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with 'objectID' and 'timestamp' columns.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with added 'track_ID' and 'frame' columns, or None if input is invalid.\n",
    "    \"\"\"\n",
    "    _objectID = \"obj_id\"\n",
    "    _timestamp = \"ts\"\n",
    "    _track_ID = \"trackId\"\n",
    "    _frame = \"frame\"\n",
    "\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print(\"Input must be a Pandas DataFrame.\")\n",
    "        return None\n",
    "\n",
    "    if not {_objectID, _timestamp}.issubset(df.columns):\n",
    "        print(\"DataFrame must contain '{}' and '{}' columns.\".format(_objectID, _timestamp))\n",
    "        return None\n",
    "\n",
    "    df = df.sort_values(by=[_objectID, _timestamp])  # Important: Sort by objectID then timestamp\n",
    "\n",
    "    track_id_map = {}  # Dictionary to store objectID to track_ID mapping\n",
    "    current_track_id = 1 # object starts from 1, track record 0 stand for no object later\n",
    "    df[_track_ID] = -1  # Initialize track_ID column\n",
    "    df[_frame] = -1       # Initialize frame column\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        object_id = row[_objectID]\n",
    "\n",
    "        if object_id not in track_id_map:\n",
    "            track_id_map[object_id] = current_track_id\n",
    "            current_track_id += 1\n",
    "\n",
    "        df.loc[index, _track_ID] = track_id_map[object_id]\n",
    "\n",
    "    # Calculate frame numbers within each track\n",
    "    df[_frame] = df.groupby(_track_ID).cumcount()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'frame' created.\n",
      "Column 'trackId' created.\n",
      "Column 'xCenter' created.\n",
      "Column 'yCenter' created.\n",
      "Column 'length' already exists.\n",
      "Column 'width' already exists.\n",
      "Column 'xVelocity' created.\n",
      "Column 'yVelocity' created.\n",
      "Column 'xAcceleration' created.\n",
      "Column 'yAcceleration' created.\n",
      "Column 'frontSightDistance' created.\n",
      "Column 'backSightDistance' created.\n",
      "Column 'dhw' created.\n",
      "Column 'thw' created.\n",
      "Column 'ttc' created.\n",
      "Column 'precedingXVelocity' created.\n",
      "Column 'precedingId' created.\n",
      "Column 'followingId' created.\n",
      "Column 'leftPrecedingId' created.\n",
      "Column 'leftAlongsideId' created.\n",
      "Column 'leftFollowingId' created.\n",
      "Column 'rightPrecedingId' created.\n",
      "Column 'rightAlongsideId' created.\n",
      "Column 'rightFollowingId' created.\n",
      "Column 'laneId' created.\n",
      "Column 'angle' created.\n",
      "Column 'orientation' created.\n",
      "Column 'yaw_rate ' created.\n",
      "Column 'ego_offset' created.\n"
     ]
    }
   ],
   "source": [
    "# sort by obj_id, make sure ego always comes first, then sort by ts stable\n",
    "\n",
    "df_obj_augment.sort_values(by='obj_id', inplace=True)\n",
    "df_obj_augment.sort_values(by='ts', inplace=True, kind='stable')\n",
    "df_obj_augment.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# First traverse to calculate the x, y, z, and speed, acceleration respectively.\n",
    "updated_col = 'updated'\n",
    "df_obj_augment[updated_col] = False \n",
    "\n",
    "curr_obj_idx, curr_ego_idx = None, None \n",
    "\n",
    "# print(df_obj_augment.head)\n",
    "df_obj_augment.to_csv('obj_before_first_trav.csv')\n",
    "\n",
    "# create all columns_tracks in df_obj_augment if needed\n",
    "df_obj_augment = ensure_columns_exist_robust(df_obj_augment, columns_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_id_col = 'obj_id'\n",
    "for idx in range(len(df_obj_augment)-1): \n",
    "    # print(\"current idx: {}\".format(idx))\n",
    "\n",
    "    # obj\n",
    "    if int(df_obj_augment.loc[idx, obj_id_col]) != ego_obj_id:\n",
    "        curr_obj_idx = idx\n",
    "\n",
    "        # check curr_obj_idx and curr_ego_idx timestamp matched\n",
    "        # print(int(df_obj_augment.loc[idx, obj_id_col]))\n",
    "        # print(\"if result {}\".format(int(df_obj_augment.loc[idx, obj_id_col]) != ego_obj_id))\n",
    "        # print(\"object {} and ego {} timestamp not match\".format(curr_obj_idx, curr_ego_idx))\n",
    "        assert df_obj_augment.loc[curr_obj_idx, 'ts'] == df_obj_augment.loc[curr_ego_idx, 'ts'], \"object {} and ego {} timestamp not match\".format(curr_obj_idx, curr_ego_idx)\n",
    "\n",
    "        # NOTE x, y \n",
    "        df_obj_augment.loc[curr_obj_idx, 'x'] = df_obj_augment.loc[curr_ego_idx, 'x'] + df_obj_augment.loc[curr_obj_idx, 'lat']\n",
    "        df_obj_augment.loc[curr_obj_idx, 'y'] = df_obj_augment.loc[curr_ego_idx, 'y'] + df_obj_augment.loc[curr_obj_idx, 'lgt']\n",
    "        \n",
    "        # flag column updated\n",
    "        df_obj_augment.loc[curr_obj_idx, updated_col] = True \n",
    "\n",
    "    # ego\n",
    "    else: \n",
    "        # print(\"update curr_ego_idx: {}\".format(idx))\n",
    "        curr_ego_idx = idx\n",
    "        curr_ego_h = df_obj_augment.loc[curr_ego_idx, 'h']\n",
    "\n",
    "        # update ego frame vel_lgt_mps, vel_lat_mps for later computation\n",
    "        df_obj_augment.loc[curr_ego_idx, 'vel_lgt_mps'] = df_obj_augment.loc[curr_ego_idx, 'spd_mps']\n",
    "        df_obj_augment.loc[curr_ego_idx, 'vel_lat_mps'] = 0\n",
    "\n",
    "    # NOTE xCenter, yCenter\n",
    "    df_obj_augment.loc[idx, 'xCenter'] = df_obj_augment.loc[idx, 'x'] \n",
    "    df_obj_augment.loc[idx, 'yCenter'] = df_obj_augment.loc[idx, 'y'] \n",
    "\n",
    "    # NOTE xVelocity, yVelocity, xAcceleration, yAcceleration\n",
    "    # update according to curr_ego_h\n",
    "    # compute all xVelocity, yVelocity, xAcceleration, yAcceleration from ground-reference-frame\n",
    "    _xVel, _yVel = rotate_vector(df_obj_augment.loc[idx, 'vel_lgt_mps'], df_obj_augment.loc[idx, 'vel_lat_mps'], curr_ego_h)\n",
    "    df_obj_augment.loc[idx, 'xVelocity'] = _xVel\n",
    "    df_obj_augment.loc[idx, 'yVelocity'] = _yVel\n",
    "\n",
    "    _xAcc, _yAcc = rotate_vector(df_obj_augment.loc[idx, 'acc_lgt_mpss'], df_obj_augment.loc[idx, 'acc_lat_mpss'], curr_ego_h)\n",
    "    df_obj_augment.loc[idx, 'xAcceleration'] = _xAcc\n",
    "    df_obj_augment.loc[idx, 'yAcceleration'] = _yAcc\n",
    "\n",
    "    # angle: cannot calculate w/out lane info\n",
    "    df_obj_augment.loc[idx, 'angle'] = 0\n",
    "\n",
    "    # orientation\n",
    "    df_obj_augment.loc[idx, 'orientation'] = df_obj_augment.loc[idx, 'h'] \n",
    "\n",
    "    # yaw_rate ~= yAcc / xVel\n",
    "    if df_obj_augment.loc[idx, 'xVelocity'] != 0:\n",
    "        df_obj_augment.loc[idx, 'yaw_rate'] = df_obj_augment.loc[idx, 'yAcceleration'] / df_obj_augment.loc[idx, 'xVelocity']\n",
    "    else:\n",
    "        df_obj_augment.loc[idx, 'yaw_rate'] = 0\n",
    "\n",
    "    # ego_offset: cannot calculate w/out lane width info, set to 0\n",
    "    df_obj_augment.loc[idx, 'ego_offset'] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tracks and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_obj_augment.to_csv('obj_first_trav.csv')\n",
    "df_tracks = create_tracks(df_obj_augment)\n",
    "df_tracks.to_csv('my_tracks.csv')\n",
    "\n",
    "# Second traverse to calculate the \"nine-positional\" detective filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9-box Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_vehicle_sides(df, current_index, lookahead_factor=2.0):\n",
    "  \"\"\"\n",
    "  Checks for vehicles in 8 directions (front, back, left_following, \n",
    "  left_preceding, left_alongside, right_preceding, right_following, right_alongside) \n",
    "  based on ts, x, y, orientation, xVelocity, and yVelocity data.\n",
    "\n",
    "  Args:\n",
    "    df: pandas DataFrame containing 'ts', 'x', 'y', 'orientation', 'obj_id', 'xVelocity', 'yVelocity' columns.\n",
    "    current_index: Index of the current vehicle in the DataFrame.\n",
    "    x_velocity: x-component of the current vehicle's velocity.\n",
    "    y_velocity: y-component of the current vehicle's velocity.\n",
    "    lookahead_factor: Factor to adjust lookahead distance based on speed.\n",
    "\n",
    "  Returns:\n",
    "    A dictionary with keys for each direction, \n",
    "    each containing the obj_id of the nearest vehicle in that direction, \n",
    "    or 0 if no vehicle is found.\n",
    "  \"\"\"\n",
    "  current_row = df.iloc[current_index]\n",
    "\n",
    "  x_velocity        = current_row['xVelocity']\n",
    "  y_velocity        = current_row['yVelocity']\n",
    "  current_x         = current_row['x']\n",
    "  current_y         = current_row['y']\n",
    "  current_timestamp = current_row['ts'] \n",
    "\n",
    "  # Calculate lookahead distance based on speed\n",
    "  current_speed     = np.sqrt(x_velocity**2 + y_velocity**2)\n",
    "  lookahead_distance = current_speed * lookahead_factor \n",
    "\n",
    "  # Calculate unit vectors for current vehicle's direction\n",
    "  heading_x = np.cos(np.radians(current_row['orientation']))\n",
    "  heading_y = np.sin(np.radians(current_row['orientation']))\n",
    "\n",
    "  # Define unit vectors for all directions\n",
    "  directions = {\n",
    "      'front': np.array([heading_x, heading_y]),\n",
    "      'back': -np.array([heading_x, heading_y]),\n",
    "      'left_alongside': np.array([-heading_y, heading_x]), \n",
    "      'left_preceding': np.array([heading_x-heading_y, heading_x+heading_y]),   # 'front' + 'left_alongside'\n",
    "      'left_following': np.array([-heading_x-heading_y, heading_x-heading_y]),  # 'back'  + 'left_alongside'\n",
    "      'right_alongside': np.array([heading_y, -heading_x]),\n",
    "      'right_preceding': np.array([heading_x+heading_y, -heading_x+heading_y]), # 'front' + 'right_alongside'\n",
    "      'right_following': np.array([-heading_x+heading_y, -heading_x-heading_y]) # 'back'  + 'right_alongside'\n",
    "  }\n",
    "\n",
    "  # Initialize results\n",
    "  vehicle_ids = {\n",
    "      'front':            (0, float('inf'), 0),  # might need precedingXVelocity\n",
    "      'back':             (0, float('inf')),\n",
    "      'left_preceding':   (0, float('inf')),\n",
    "      'left_alongside':   (0, float('inf')),\n",
    "      'left_following':   (0, float('inf')),\n",
    "      'right_preceding':  (0, float('inf')),\n",
    "      'right_alongside':  (0, float('inf')),\n",
    "      'right_following':  (0, float('inf'))\n",
    "  }\n",
    "\n",
    "  # Filter DataFrame to consider only vehicles within a reasonable time window\n",
    "  # (e.g., vehicles within the last few seconds)\n",
    "  time_window = 10**6  # 1 second,  10**6, unit: microsecond\n",
    "  filtered_df = df[(df['ts'] >= current_timestamp - time_window) & (df['ts'] <= current_timestamp + time_window)] \n",
    "\n",
    "  for index, row in filtered_df.iterrows():\n",
    "    if index == current_index:\n",
    "      continue  # Skip the current vehicle\n",
    "\n",
    "    # Calculate distance and direction vectors\n",
    "    distance_vector = np.array([row['x'] - current_x, row['y'] - current_y])\n",
    "    distance = np.linalg.norm(distance_vector)\n",
    "\n",
    "    # Check if within lookahead distance\n",
    "    if distance > lookahead_distance:\n",
    "      continue\n",
    "\n",
    "    # Normalize direction vector\n",
    "    direction_vector = distance_vector / distance\n",
    "\n",
    "    for direction, direction_unit_vector in directions.items():\n",
    "      # loop through all directions\n",
    "\n",
    "      dot_product = np.dot(direction_vector, direction_unit_vector)\n",
    "\n",
    "      if dot_product > 0:\n",
    "        # on the same direction\n",
    "\n",
    "        if not vehicle_ids[direction][0] or distance < vehicle_ids[direction][1]:\n",
    "          # not exist or closer than current obj_id, then udpate\n",
    "\n",
    "          # front contains xVelocity\n",
    "          if direction == 'front':\n",
    "            vehicle_ids[direction] = (row['obj_id'], distance, row['xVelocity'])\n",
    "            continue\n",
    "\n",
    "          vehicle_ids[direction] = (row['obj_id'], distance)\n",
    "\n",
    "  return vehicle_ids\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_surrounding_objects(df):\n",
    "    \"\"\"\n",
    "    Assuming 'df' is your DataFrame with 'ts', 'x', 'y', 'orientation', 'obj_id', 'xVelocity', 'yVelocity' columns\n",
    "    \"\"\"\n",
    "    # for _timestamp, _group_indices in df.groupby('ts').groups.items():\n",
    "        # _df_timestamp = df.loc[_group_indices] \n",
    "        # for _index, _ in _df_timestamp.iterrows():\n",
    "            # surrounding_results = check_vehicle_sides(_df_timestamp, _index) \n",
    "            # surrounding_results = check_vehicle_sides(df, _index) \n",
    "\n",
    "    for _index in df.index:\n",
    "        surrounding_results = check_vehicle_sides(df, _index) \n",
    "\n",
    "        # update precedingXVelocity\n",
    "        df.loc[_index, 'precedingXVelocity'] = surrounding_results['front'][2]\n",
    "\n",
    "        # update surrounding values\n",
    "        df.loc[_index, 'precedingId']      =  surrounding_results['front']          [0]\n",
    "        df.loc[_index, 'followingId']      =  surrounding_results['back']           [0]\n",
    "        df.loc[_index, 'leftPrecedingId']  =  surrounding_results['left_preceding'] [0]\n",
    "        df.loc[_index, 'leftAlongsideId']  =  surrounding_results['left_alongside'] [0]\n",
    "        df.loc[_index, 'leftFollowingId']  =  surrounding_results['left_following'] [0]\n",
    "        df.loc[_index, 'rightPrecedingId'] =  surrounding_results['right_preceding'][0]\n",
    "        df.loc[_index, 'rightAlongsideId'] =  surrounding_results['right_alongside'][0]\n",
    "        df.loc[_index, 'rightFollowingId'] =  surrounding_results['right_following'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Traverse to Calculate 9-box detector\n",
    "# check_surrounding_objects(df_tracks)\n",
    "check_surrounding_objects(df_obj_augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obj_augment.to_csv(\"nine_box_tracks.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct three output dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_tracks = pd.read_csv('01_tracksMeta.csv')\n",
    "# print(pd_tracks.columns)\n",
    "\n",
    "# Construct 3 output dataframes\n",
    "pd_recording_meta = pd.DataFrame(columns=columns_recording_meta)\n",
    "pd_tracks_meta = pd.DataFrame(columns=columns_tracks_meta)\n",
    "pd_tracks = pd.DataFrame(columns=columns_tracks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct pd_tracks values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_tracks['xCenter'] = df_obj_augment['x']\n",
    "# pd_tracks['yCenter'] = df_obj_augment['y']\n",
    "# pd_tracks['length'] = df_obj_augment['length']\n",
    "# pd_tracks['width'] = df_obj_augment['width']\n",
    "# pd_tracks['xVelocity']          = pd.NA \n",
    "# pd_tracks['yVelocity']          = pd.NA \n",
    "# pd_tracks['xAcceleration']      = pd.NA \n",
    "# pd_tracks['yAcceleration']      = pd.NA \n",
    "# pd_tracks['frontSightDistance'] = pd.NA \n",
    "# pd_tracks['backSightDistance']  = pd.NA \n",
    "# pd_tracks['dhw']                = pd.NA \n",
    "# pd_tracks['thw']                = pd.NA \n",
    "# pd_tracks['ttc']                = pd.NA \n",
    "\n",
    "# # Nine-box data\n",
    "# # NOTE: initial to -1 indicate invalid value\n",
    "# pd_tracks['precedingXVelocity'] = pd.NA \n",
    "# pd_tracks['precedingId']        = pd.NA \n",
    "# pd_tracks['followingId']        = pd.NA \n",
    "# pd_tracks['leftPrecedingId']    = pd.NA \n",
    "# pd_tracks['leftAlongsideId']    = pd.NA \n",
    "# pd_tracks['leftFollowingId']    = pd.NA \n",
    "# pd_tracks['rightPrecedingId']   = pd.NA \n",
    "# pd_tracks['rightAlongsideId']   = pd.NA \n",
    "# pd_tracks['rightFollowingId']   = pd.NA \n",
    "\n",
    "# pd_tracks['laneId']      = df_obj_augment['lane_id']\n",
    "# pd_tracks['angle']       = df_obj_augment['h']\n",
    "# pd_tracks['orientation'] = pd.NA \n",
    "# pd_tracks['yaw_rate ']   = pd.NA \n",
    "# pd_tracks['ego_offset']  = pd.NA \n",
    "\n",
    "# # Extra columns\n",
    "# pd_tracks['roadID'] = df_obj_augment['road_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct pd_tracks_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trackId</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>initialFrame</th>\n",
       "      <th>finalFrame</th>\n",
       "      <th>numFrames</th>\n",
       "      <th>class</th>\n",
       "      <th>drivingDirection</th>\n",
       "      <th>traveledDistance</th>\n",
       "      <th>minXVelocity</th>\n",
       "      <th>maxXVelocity</th>\n",
       "      <th>meanXVelocity</th>\n",
       "      <th>minDHW</th>\n",
       "      <th>minTHW</th>\n",
       "      <th>minTTC</th>\n",
       "      <th>numLaneChanges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [trackId, length, width, initialFrame, finalFrame, numFrames, class, drivingDirection, traveledDistance, minXVelocity, maxXVelocity, meanXVelocity, minDHW, minTHW, minTTC, numLaneChanges]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_tracks_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct pd_recording_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordingId</th>\n",
       "      <th>frameRate</th>\n",
       "      <th>locationId</th>\n",
       "      <th>speedLimit</th>\n",
       "      <th>month</th>\n",
       "      <th>weekDay</th>\n",
       "      <th>startTime</th>\n",
       "      <th>duration</th>\n",
       "      <th>totalDrivenDistance</th>\n",
       "      <th>totalDrivenTime</th>\n",
       "      <th>numVehicles</th>\n",
       "      <th>numCars</th>\n",
       "      <th>numTrucks</th>\n",
       "      <th>numBuses</th>\n",
       "      <th>laneMarkings</th>\n",
       "      <th>scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [recordingId, frameRate, locationId, speedLimit, month, weekDay, startTime, duration, totalDrivenDistance, totalDrivenTime, numVehicles, numCars, numTrucks, numBuses, laneMarkings, scale]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd_recording_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store All three outputs to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tracks.to_csv('tracks_result.csv')\n",
    "pd_tracks_meta.to_csv('tracks_meta_result.csv')\n",
    "pd_recording_meta.to_csv('recording_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
