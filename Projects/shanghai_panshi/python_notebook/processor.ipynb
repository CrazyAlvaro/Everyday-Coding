{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "###########################################\n",
    "# Configuation\n",
    "###########################################\n",
    "\n",
    "# Assume laneId provided in preceeding data processor\n",
    "lane_id_col = 'lane_id'\n",
    "columns_tracks = ['frame', 'trackId', 'timestamp', 'vehicle_id', 'xCenter', 'yCenter', 'length', 'width',\n",
    "                'height', 'xVelocity', 'yVelocity', 'xAcceleration', 'yAcceleration',\n",
    "                'frontSightDistance', 'backSightDistance', 'dhw', 'thw', 'ttc',\n",
    "                'precedingXVelocity', 'precedingId', 'followingId', 'leftPrecedingId',\n",
    "                'leftAlongsideId', 'leftFollowingId', 'rightPrecedingId',\n",
    "                'rightAlongsideId', 'rightFollowingId', 'roadId', 'laneId', 'angle',\n",
    "                'orientation', 'yaw', 'yaw_rate', 'ego_offset']\n",
    "columns_tracks_meta = ['trackId', 'length', 'width', 'initialFrame', 'finalFrame', 'numFrames',\n",
    "       'class', 'drivingDirection', 'traveledDistance', 'minXVelocity',\n",
    "       'maxXVelocity', 'meanXVelocity', 'minDHW', 'minTHW', 'minTTC',\n",
    "       'numLaneChanges'] \n",
    "columns_recording_meta = ['recordingId', 'frameRate', 'locationId', 'speedLimit', 'month',\n",
    "       'weekDay', 'startTime', 'duration', 'totalDrivenDistance',\n",
    "       'totalDrivenTime', 'numVehicles', 'numCars', 'numTrucks', 'numBuses',\n",
    "       'laneMarkings', 'scale']\n",
    "\n",
    "\n",
    "# 读取多个CSV文件\n",
    "# df_ego = pd.read_csv(\"ego.csv\", index_col='ts', parse_dates=['ts'], date_format=parse_timestamp)\n",
    "# df_obj = pd.read_csv(\"obj.csv\", index_col='ts', parse_dates=['ts'], date_format=parse_timestamp)\n",
    "df_ego = pd.read_csv(\"../ego.csv\")\n",
    "df_obj = pd.read_csv(\"../obj.csv\")\n",
    "# ... 其他传感器文件\n",
    "\n",
    "# df_ego 加入 obj_id 字段 取 1\n",
    "ego_obj_id = 1\n",
    "df_ego['obj_id'] = ego_obj_id \n",
    "\n",
    "# NOTE: Assume we have laneId \n",
    "# add column 'laneId' to both ego and obj if needed\n",
    "if lane_id_col not in df_ego.columns:\n",
    "    df_ego[lane_id_col] = 0\n",
    "\n",
    "if lane_id_col not in df_obj.columns:\n",
    "    df_obj[lane_id_col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(df_ego['obj_id'].isnull().any())\n",
    "print(df_obj['obj_id'].isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " [NoUse]Check obj_id of merge dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing nano seconds timestamp\n",
    "\n",
    "# 合并DataFrame\n",
    "# df_merged = pd.concat([df_ego, df_obj], axis=0, ignore_index=True)\n",
    "\n",
    "# 处理缺失值（例如填充为0）\n",
    "# df_merged.fillna(0, inplace=True)\n",
    "\n",
    "# check obj_id\n",
    "# print(df_merged['obj_id'].head)\n",
    "# print(f\"if any obj_id is NaN:{df_merged['obj_id'].isnull().any()}\\n\")\n",
    "# print(f\"Number of rows : {len(df_merged)}\")\n",
    "# print(f\"Number of unique obj_id: {df_merged['obj_id'].nunique()}\")\n",
    "\n",
    "# print(f\"Number of unique ts: {df_merged['ts'].nunique()}\")\n",
    "\n",
    "# print(f\"Number of unique ts in obj: {df_obj['ts'].nunique()}\")\n",
    "# print(f\"Number of unique ts in ego: {df_ego['ts'].nunique()}\")\n",
    "\n",
    "# 查看合并后的DataFrame\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Interpolation in ego"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data timestamp arrange \n",
    "\n",
    "add obj's unique ts to ego, then interpolate new ts in ego from existing ts\n",
    "\n",
    "Since we need ego state in all ts of obj, we need to estimate the state data of ego in all obj ts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique ts in obj: 299\n",
      "unique ts in ego: 998\n",
      "unique ts in obj_not_ego: 298\n"
     ]
    }
   ],
   "source": [
    "ts_obj = df_obj['ts'].unique()\n",
    "ts_ego = df_ego['ts'].unique()\n",
    "ts_obj_not_ego = [ts for ts in ts_obj if ts not in ts_ego]\n",
    "\n",
    "print(f\"unique ts in obj: {len(ts_obj)}\")\n",
    "print(f\"unique ts in ego: {len(ts_ego)}\")\n",
    "print(f\"unique ts in obj_not_ego: {len(ts_obj_not_ego)}\")\n",
    "\n",
    "# augment ego with ts in obj\n",
    "df_obj_ts = pd.DataFrame(np.array(ts_obj_not_ego), columns=['ts'])\n",
    "\n",
    "# concat with df_ego\n",
    "df_ego_augment = pd.concat([df_ego, df_obj_ts], axis=0, ignore_index=True)\n",
    "\n",
    "# sort by ts and reindex\n",
    "df_ego_augment.sort_values(by='ts', inplace=True)\n",
    "df_ego_augment.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# update obj_id of new rows\n",
    "df_ego_augment['obj_id'] = ego_obj_id \n",
    "\n",
    "# store middle data to csv\n",
    "# df_ego_augment.to_csv('ego_augment.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation of ego in obj ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation for x, y values\n",
    "\n",
    "# 1 create new index with ts\n",
    "df_ego_augment['timestamp'] = pd.to_datetime(df_ego_augment['ts'])\n",
    "df_ego_augment.set_index('timestamp', inplace=True)\n",
    "\n",
    "df_ego_augment.to_csv('ego_augment.csv', index=False)\n",
    "# df_ego_augment.to_csv('ego_augment.csv', index=True)\n",
    "\n",
    "# 2 interpolate columns with time method by index\n",
    "time_interpolate_columns = ['x','y','z','h','spd_mps', 'spd_kph', 'acc_lgt_mpss', 'acc_lat_mpss']\n",
    "shift_interpolate_columns = ['road_id', 'lane_id']\n",
    "\n",
    "# create a new dataframe but share underline value for memory optimization\n",
    "df_ego_interpolated = df_ego_augment.copy(deep=False)\n",
    "\n",
    "for col in time_interpolate_columns:\n",
    "    df_ego_interpolated[col] = df_ego_interpolated[col].interpolate(method='time')\n",
    "\n",
    "for col in shift_interpolate_columns:\n",
    "    df_ego_interpolated[col] = df_ego_interpolated[col].ffill()\n",
    "\n",
    "# set ego length, width to 0, since we don't know\n",
    "df_ego_interpolated['length'] = 0\n",
    "df_ego_interpolated['width']  = 0\n",
    "\n",
    "# assume ego is car\n",
    "df_ego_interpolated['class_str']  = 'car' \n",
    "df_ego_interpolated.to_csv('ego_augment_interpolated.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat df_ego_interpolated and df_obj to df_obj_augment\n",
    "here df_obj_augment has all obj_id (obj and ego), with each obj's ts has ego position interpolated from previous processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# concat df_ego_augment to df_obj for late obj axis transform to ground axis\n",
    "df_obj_augment = pd.concat([df_obj, df_ego_interpolated], axis=0)\n",
    "\n",
    "# sort all vehicles by ts-timestamp value\n",
    "df_obj_augment.sort_values(by='ts', inplace=True)\n",
    "\n",
    "# sort dataframe for reviewing\n",
    "df_obj_augment.to_csv('obj_augment.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obj Track Computation from ego data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yechenhuang/.pyenv/versions/3.10.15/lib/python3.10/site-packages/pandas/core/indexing.py:2421: FutureWarning: Dtype inference on a pandas object (Series, Index, ExtensionArray) is deprecated. The Index constructor will keep the original dtype in the future. Call `infer_objects` on the result to get the old behavior.\n",
      "  new_ix = Index(new_ix)\n"
     ]
    }
   ],
   "source": [
    "# set ego vel_lgt_mps, vel_lat_mps\n",
    "df_obj_augment.loc[df_obj_augment['obj_id'] == ego_obj_id, 'vel_lgt_mps'] = df_obj_augment['spd_mps']\n",
    "df_obj_augment.loc[df_obj_augment['obj_id'] == ego_obj_id, 'vel_lat_mps'] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traverse obj_augment to axis transformation\n",
    "\n",
    "update obj's x and y position according to ego's x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_columns_exist_robust(df, column_names):\n",
    "    \"\"\"\n",
    "    Robust version of ensure_columns_exist, handling potential errors.\n",
    "\n",
    "    Args:\n",
    "        df: The Pandas DataFrame.\n",
    "        column_names: A list of strings representing column names.\n",
    "\n",
    "    Returns:\n",
    "        The DataFrame, potentially with new columns added, or None if an error occurs.\n",
    "        Prints messages indicating actions taken or errors.\n",
    "    \"\"\"\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print(\"Error: Input 'df' must be a Pandas DataFrame.\")\n",
    "        return None\n",
    "\n",
    "    if not column_names:  # Handle empty list of column names\n",
    "        print(\"No column names provided. Nothing to do.\")\n",
    "        return df\n",
    "\n",
    "    if not all(isinstance(col, str) for col in column_names):\n",
    "        print(\"Error: All elements in 'column_names' must be strings.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        for col_name in column_names:\n",
    "            if col_name not in df.columns:\n",
    "                df[col_name] = pd.NA\n",
    "                print(f\"Column '{col_name}' created.\")\n",
    "            else:\n",
    "                print(f\"Column '{col_name}' already exists.\")\n",
    "        return df\n",
    "    except Exception as e: # Catch potential exceptions during column creation\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_vector(x1, y1, angle_radians):\n",
    "    \"\"\"\n",
    "    Rotates a vector from one coordinate system (RF1) to another (RF2).\n",
    "\n",
    "    Args:\n",
    "        x1: The x-component of the vector in RF1.\n",
    "        y1: The y-component of the vector in RF1.\n",
    "        angle_radians: The angle of rotation from RF1 to RF2, measured counter-clockwise.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the x and y components of the rotated vector in RF2 (x2, y2).\n",
    "        Returns None if input is invalid.\n",
    "    \"\"\"\n",
    "    if not isinstance(x1, (int, float)) or not isinstance(y1, (int, float)) or not isinstance(angle_radians, (int, float)):\n",
    "      print(\"x1, y1 and angle must be numbers\")\n",
    "      return None\n",
    "\n",
    "    x2 = x1 * math.cos(angle_radians) - y1 * math.sin(angle_radians)\n",
    "    y2 = x1 * math.sin(angle_radians) + y1 * math.cos(angle_radians)\n",
    "    return (x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tracks(df):\n",
    "    \"\"\"\n",
    "    Assigns unique track IDs and frame numbers to objects in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with 'objectID' and 'timestamp' columns.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with added 'track_ID' and 'frame' columns, or None if input is invalid.\n",
    "    \"\"\"\n",
    "    _objectID = \"obj_id\"\n",
    "    _timestamp = \"ts\"\n",
    "    _track_ID = \"trackId\"\n",
    "    _frame = \"frame\"\n",
    "\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print(\"Input must be a Pandas DataFrame.\")\n",
    "        return None\n",
    "\n",
    "    if not {_objectID, _timestamp}.issubset(df.columns):\n",
    "        print(\"DataFrame must contain '{}' and '{}' columns.\".format(_objectID, _timestamp))\n",
    "        return None\n",
    "\n",
    "    df = df.sort_values(by=[_objectID, _timestamp])  # Important: Sort by objectID then timestamp\n",
    "\n",
    "    track_id_map = {}  # Dictionary to store objectID to track_ID mapping\n",
    "    current_track_id = 1 # object starts from 1, track record 0 stand for no object later\n",
    "    df[_track_ID] = -1  # Initialize track_ID column\n",
    "    df[_frame] = -1       # Initialize frame column\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        object_id = row[_objectID]\n",
    "\n",
    "        if object_id not in track_id_map:\n",
    "            track_id_map[object_id] = current_track_id\n",
    "            current_track_id += 1\n",
    "\n",
    "        df.loc[index, _track_ID] = track_id_map[object_id]\n",
    "\n",
    "    # Calculate frame numbers within each track\n",
    "    df[_frame] = df.groupby(_track_ID).cumcount()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'frame' created.\n",
      "Column 'trackId' created.\n",
      "Column 'timestamp' created.\n",
      "Column 'vehicle_id' created.\n",
      "Column 'xCenter' created.\n",
      "Column 'yCenter' created.\n",
      "Column 'length' already exists.\n",
      "Column 'width' already exists.\n",
      "Column 'height' already exists.\n",
      "Column 'xVelocity' created.\n",
      "Column 'yVelocity' created.\n",
      "Column 'xAcceleration' created.\n",
      "Column 'yAcceleration' created.\n",
      "Column 'frontSightDistance' created.\n",
      "Column 'backSightDistance' created.\n",
      "Column 'dhw' created.\n",
      "Column 'thw' created.\n",
      "Column 'ttc' created.\n",
      "Column 'precedingXVelocity' created.\n",
      "Column 'precedingId' created.\n",
      "Column 'followingId' created.\n",
      "Column 'leftPrecedingId' created.\n",
      "Column 'leftAlongsideId' created.\n",
      "Column 'leftFollowingId' created.\n",
      "Column 'rightPrecedingId' created.\n",
      "Column 'rightAlongsideId' created.\n",
      "Column 'rightFollowingId' created.\n",
      "Column 'roadId' created.\n",
      "Column 'laneId' created.\n",
      "Column 'angle' created.\n",
      "Column 'orientation' created.\n",
      "Column 'yaw' created.\n",
      "Column 'yaw_rate' created.\n",
      "Column 'ego_offset' created.\n"
     ]
    }
   ],
   "source": [
    "# sort by obj_id, make sure ego always comes first, then sort by ts stable\n",
    "\n",
    "df_obj_augment.sort_values(by='obj_id', inplace=True)\n",
    "df_obj_augment.sort_values(by='ts', inplace=True, kind='stable')\n",
    "df_obj_augment.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# First traverse to calculate the x, y, z, and speed, acceleration respectively.\n",
    "updated_col = 'updated'\n",
    "df_obj_augment[updated_col] = False \n",
    "\n",
    "curr_obj_idx, curr_ego_idx = None, None \n",
    "\n",
    "# print(df_obj_augment.head)\n",
    "df_obj_augment.to_csv('obj_before_first_trav.csv')\n",
    "\n",
    "# create all columns_tracks in df_obj_augment if needed\n",
    "df_obj_augment = ensure_columns_exist_robust(df_obj_augment, columns_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_id_col = 'obj_id'\n",
    "for idx in range(len(df_obj_augment)-1): \n",
    "    # print(\"current idx: {}\".format(idx))\n",
    "\n",
    "    # obj\n",
    "    if int(df_obj_augment.loc[idx, obj_id_col]) != ego_obj_id:\n",
    "        curr_obj_idx = idx\n",
    "\n",
    "        # check curr_obj_idx and curr_ego_idx timestamp matched\n",
    "        # print(int(df_obj_augment.loc[idx, obj_id_col]))\n",
    "        # print(\"if result {}\".format(int(df_obj_augment.loc[idx, obj_id_col]) != ego_obj_id))\n",
    "        # print(\"object {} and ego {} timestamp not match\".format(curr_obj_idx, curr_ego_idx))\n",
    "        assert df_obj_augment.loc[curr_obj_idx, 'ts'] == df_obj_augment.loc[curr_ego_idx, 'ts'], \"object {} and ego {} timestamp not match\".format(curr_obj_idx, curr_ego_idx)\n",
    "\n",
    "        # NOTE update according to curr_ego_h\n",
    "        # NOTE compute all x, y, xVelocity, yVelocity, xAcceleration, yAcceleration from ground-reference-frame\n",
    "        _x, _y = rotate_vector(df_obj_augment.loc[idx, 'lgt'], df_obj_augment.loc[idx, 'lat'], curr_ego_h)\n",
    "        df_obj_augment.loc[curr_obj_idx, 'x'] = df_obj_augment.loc[curr_ego_idx, 'x'] + _x\n",
    "        df_obj_augment.loc[curr_obj_idx, 'y'] = df_obj_augment.loc[curr_ego_idx, 'y'] + _y\n",
    "\n",
    "        _xVel, _yVel = rotate_vector(df_obj_augment.loc[idx, 'vel_lgt_mps'], df_obj_augment.loc[idx, 'vel_lat_mps'], curr_ego_h)\n",
    "        df_obj_augment.loc[curr_obj_idx, 'xVelocity'] = df_obj_augment.loc[curr_ego_idx, 'xVelocity'] + _xVel\n",
    "        df_obj_augment.loc[curr_obj_idx, 'yVelocity'] = df_obj_augment.loc[curr_ego_idx, 'yVelocity'] + _yVel\n",
    "    \n",
    "        _xAcc, _yAcc = rotate_vector(df_obj_augment.loc[idx, 'acc_lgt_mpss'], df_obj_augment.loc[idx, 'acc_lat_mpss'], curr_ego_h)\n",
    "        df_obj_augment.loc[curr_obj_idx, 'xAcceleration'] = df_obj_augment.loc[curr_ego_idx, 'xAcceleration'] + _xAcc\n",
    "        df_obj_augment.loc[curr_obj_idx, 'yAcceleration'] = df_obj_augment.loc[curr_ego_idx, 'yAcceleration'] + _yAcc\n",
    "        \n",
    "        # flag column updated\n",
    "        df_obj_augment.loc[curr_obj_idx, updated_col] = True \n",
    "\n",
    "    # ego\n",
    "    else: \n",
    "        # print(\"update curr_ego_idx: {}\".format(idx))\n",
    "        curr_ego_idx = idx\n",
    "        curr_ego_h = df_obj_augment.loc[curr_ego_idx, 'h']\n",
    "\n",
    "        # update ego frame vel_lgt_mps, vel_lat_mps for later computation\n",
    "        df_obj_augment.loc[curr_ego_idx, 'xVelocity'] = df_obj_augment.loc[curr_ego_idx, 'spd_mps']\n",
    "        df_obj_augment.loc[curr_ego_idx, 'yVelocity'] = 0\n",
    "\n",
    "        _xAcc, _yAcc = rotate_vector(df_obj_augment.loc[idx, 'acc_lgt_mpss'], df_obj_augment.loc[idx, 'acc_lat_mpss'], curr_ego_h)\n",
    "        df_obj_augment.loc[curr_ego_idx, 'xAcceleration'] = _xAcc\n",
    "        df_obj_augment.loc[curr_ego_idx, 'yAcceleration'] = _yAcc\n",
    "\n",
    "    # NOTE xCenter, yCenter\n",
    "    df_obj_augment.loc[idx, 'xCenter'] = df_obj_augment.loc[idx, 'x'] \n",
    "    df_obj_augment.loc[idx, 'yCenter'] = df_obj_augment.loc[idx, 'y'] \n",
    "\n",
    "    # angle: cannot calculate w/out lane info\n",
    "    df_obj_augment.loc[idx, 'angle'] = 0\n",
    "\n",
    "    # orientation\n",
    "    df_obj_augment.loc[idx, 'orientation'] = df_obj_augment.loc[idx, 'h'] \n",
    "\n",
    "    # yaw_rate ~= yAcc / xVel\n",
    "    if df_obj_augment.loc[idx, 'xVelocity'] != 0:\n",
    "        df_obj_augment.loc[idx, 'yaw_rate'] = df_obj_augment.loc[idx, 'yAcceleration'] / df_obj_augment.loc[idx, 'xVelocity']\n",
    "    else:\n",
    "        df_obj_augment.loc[idx, 'yaw_rate'] = 0\n",
    "\n",
    "    # ego_offset: cannot calculate w/out lane width info, set to 0\n",
    "    df_obj_augment.loc[idx, 'ego_offset'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_obj_augment.to_csv('obj_first_trav.csv')\n",
    "\n",
    "# Second traverse to calculate the \"nine-positional\" detective filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9-box Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_vehicle_sides(df, current_index, lookahead_factor=2.0):\n",
    "  \"\"\"\n",
    "  Checks for vehicles in 8 directions (front, back, left_following, \n",
    "  left_preceding, left_alongside, right_preceding, right_following, right_alongside) \n",
    "  based on ts, x, y, orientation, xVelocity, and yVelocity data.\n",
    "\n",
    "  Args:\n",
    "    df: pandas DataFrame containing 'ts', 'x', 'y', 'orientation', 'obj_id', 'xVelocity', 'yVelocity' columns.\n",
    "    current_index: Index of the current vehicle in the DataFrame.\n",
    "    x_velocity: x-component of the current vehicle's velocity.\n",
    "    y_velocity: y-component of the current vehicle's velocity.\n",
    "    lookahead_factor: Factor to adjust lookahead distance based on speed.\n",
    "\n",
    "  Returns:\n",
    "    A dictionary with keys for each direction, \n",
    "    each containing the obj_id of the nearest vehicle in that direction, \n",
    "    or 0 if no vehicle is found.\n",
    "  \"\"\"\n",
    "  current_row = df.iloc[current_index]\n",
    "\n",
    "  curr_obj_id       = current_row['obj_id']\n",
    "  x_velocity        = current_row['xVelocity']\n",
    "  y_velocity        = current_row['yVelocity']\n",
    "  current_x         = current_row['x']\n",
    "  current_y         = current_row['y']\n",
    "  current_timestamp = current_row['ts']\n",
    "\n",
    "  # Calculate lookahead distance based on speed\n",
    "  current_speed     = np.sqrt(x_velocity**2 + y_velocity**2)\n",
    "  lookahead_distance = current_speed * lookahead_factor \n",
    "\n",
    "  # Calculate unit vectors for current vehicle's direction\n",
    "  heading_x = np.cos(np.radians(current_row['orientation']))\n",
    "  heading_y = np.sin(np.radians(current_row['orientation']))\n",
    "\n",
    "  # Define unit vectors for all directions\n",
    "  directions = {\n",
    "      'front': np.array([heading_x, heading_y]),\n",
    "      'back': -np.array([heading_x, heading_y]),\n",
    "      'left_alongside': np.array([-heading_y, heading_x]), \n",
    "      'left_preceding': np.array([heading_x-heading_y, heading_x+heading_y]),   # 'front' + 'left_alongside'\n",
    "      'left_following': np.array([-heading_x-heading_y, heading_x-heading_y]),  # 'back'  + 'left_alongside'\n",
    "      'right_alongside': np.array([heading_y, -heading_x]),\n",
    "      'right_preceding': np.array([heading_x+heading_y, -heading_x+heading_y]), # 'front' + 'right_alongside'\n",
    "      'right_following': np.array([-heading_x+heading_y, -heading_x-heading_y]) # 'back'  + 'right_alongside'\n",
    "  }\n",
    "\n",
    "  # Initialize results\n",
    "  vehicle_ids = {\n",
    "      'front':            (0, float('inf'), 0),  # need precedingXVelocity\n",
    "      'back':             (0, float('inf')),\n",
    "      'left_preceding':   (0, float('inf')),\n",
    "      'left_alongside':   (0, float('inf')),\n",
    "      'left_following':   (0, float('inf')),\n",
    "      'right_preceding':  (0, float('inf')),\n",
    "      'right_alongside':  (0, float('inf')),\n",
    "      'right_following':  (0, float('inf'))\n",
    "  }\n",
    "\n",
    "  # Filter DataFrame to consider only vehicles within a reasonable time window\n",
    "  # (e.g., vehicles within the last few seconds)\n",
    "  time_window = 10**6  # 1 second,  10**6, unit: microsecond\n",
    "  filtered_df = df[(df['ts'] >= current_timestamp - time_window) & (df['ts'] <= current_timestamp + time_window)] \n",
    "\n",
    "  for index, row in filtered_df.iterrows():\n",
    "    if index == current_index:\n",
    "      continue  # Skip the current vehicle\n",
    "\n",
    "    if row['obj_id'] == curr_obj_id:\n",
    "      continue  # Skip check with itself on other timestamp\n",
    "\n",
    "    # Calculate distance and direction vectors\n",
    "    distance_vector = np.array([row['x'] - current_x, row['y'] - current_y])\n",
    "    distance = np.linalg.norm(distance_vector)\n",
    "\n",
    "    # Check if within lookahead distance\n",
    "    if distance > lookahead_distance:\n",
    "      continue\n",
    "\n",
    "    # Normalize direction vector\n",
    "    direction_vector = distance_vector / distance\n",
    "\n",
    "    for direction, direction_unit_vector in directions.items():\n",
    "      # loop through all directions\n",
    "\n",
    "      dot_product = np.dot(direction_vector, direction_unit_vector)\n",
    "\n",
    "      if dot_product > 0:\n",
    "        # on the same direction\n",
    "\n",
    "        if not vehicle_ids[direction][0] or distance < vehicle_ids[direction][1]:\n",
    "          # not exist or closer than current obj_id, then udpate\n",
    "\n",
    "          # front contains xVelocity\n",
    "          if direction == 'front':\n",
    "            vehicle_ids[direction] = (row['obj_id'], distance, row['xVelocity'])\n",
    "            continue\n",
    "\n",
    "          vehicle_ids[direction] = (row['obj_id'], distance)\n",
    "\n",
    "  return vehicle_ids\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_surrounding_objects(df):\n",
    "    \"\"\"\n",
    "    Assuming 'df' is your DataFrame with 'ts', 'x', 'y', 'orientation', 'obj_id', 'xVelocity', 'yVelocity' columns\n",
    "    \"\"\"\n",
    "    # for _timestamp, _group_indices in df.groupby('ts').groups.items():\n",
    "        # _df_timestamp = df.loc[_group_indices] \n",
    "        # for _index, _ in _df_timestamp.iterrows():\n",
    "            # surrounding_results = check_vehicle_sides(_df_timestamp, _index) \n",
    "            # surrounding_results = check_vehicle_sides(df, _index) \n",
    "\n",
    "    for _index in df.index:\n",
    "        surrounding_results = check_vehicle_sides(df, _index) \n",
    "\n",
    "        # update precedingId, dhw, precedingXVelocity\n",
    "        df.loc[_index, 'precedingId']      =  surrounding_results['front']          [0]\n",
    "        if df.loc[_index, 'precedingId'] != 0:\n",
    "            df.loc[_index, 'dhw'] = surrounding_results['front'][1]\n",
    "        else:\n",
    "            # no precedingId exist\n",
    "            df.loc[_index, 'dhw'] = 0\n",
    "        df.loc[_index, 'precedingXVelocity'] = surrounding_results['front'][2]\n",
    "\n",
    "        # update surrounding values\n",
    "        df.loc[_index, 'followingId']      =  surrounding_results['back']           [0]\n",
    "        df.loc[_index, 'leftPrecedingId']  =  surrounding_results['left_preceding'] [0]\n",
    "        df.loc[_index, 'leftAlongsideId']  =  surrounding_results['left_alongside'] [0]\n",
    "        df.loc[_index, 'leftFollowingId']  =  surrounding_results['left_following'] [0]\n",
    "        df.loc[_index, 'rightPrecedingId'] =  surrounding_results['right_preceding'][0]\n",
    "        df.loc[_index, 'rightAlongsideId'] =  surrounding_results['right_alongside'][0]\n",
    "        df.loc[_index, 'rightFollowingId'] =  surrounding_results['right_following'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Traverse to Calculate 9-box detector\n",
    "# check_surrounding_objects(df_tracks)\n",
    "check_surrounding_objects(df_obj_augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ttc(df):\n",
    "    \"\"\"\n",
    "    Calculates Time-to-Collision (TTC) for each row in the DataFrame.\n",
    "\n",
    "    Args:\n",
    "      df: pandas DataFrame with columns: 'precedingId', 'xVelocity', 'precedingXVelocity', 'frontSightDistance'\n",
    "\n",
    "    Returns:\n",
    "      A new DataFrame with an additional column 'TTC'.\n",
    "    \"\"\"\n",
    "    df['ttc'] = 0 # Initialize TTC to 0 \n",
    "    df['ttc'] = df['ttc'].astype(float)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if row['precedingId'] != 0: \n",
    "            # If a preceding vehicle exists\n",
    "            relative_velocity = row['xVelocity'] - row['precedingXVelocity'] \n",
    "            if relative_velocity > 0:  # Ego vehicle is faster than preceding vehicle\n",
    "                df.loc[index, 'ttc'] = row['dhw'] / relative_velocity\n",
    "\n",
    "            df.loc[index, 'thw'] = row['dhw'] / row['xVelocity']\n",
    "        else:\n",
    "            # no preceding vehicle exist\n",
    "            df.loc[index, 'thw'] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obj_augment = calculate_ttc(df_obj_augment)\n",
    "df_obj_augment.to_csv(\"nine_box_tracks.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct three output dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_tracks = pd.read_csv('01_tracksMeta.csv')\n",
    "# print(pd_tracks.columns)\n",
    "\n",
    "# Construct 3 output dataframes\n",
    "pd_recording_meta = pd.DataFrame(columns=columns_recording_meta)\n",
    "pd_tracks_meta = pd.DataFrame(columns=columns_tracks_meta)\n",
    "pd_tracks = pd.DataFrame(columns=columns_tracks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct pd_tracks values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_tracks['xCenter'] = df_obj_augment['x']\n",
    "# pd_tracks['yCenter'] = df_obj_augment['y']\n",
    "# pd_tracks['length'] = df_obj_augment['length']\n",
    "# pd_tracks['width'] = df_obj_augment['width']\n",
    "# pd_tracks['xVelocity']          = pd.NA \n",
    "# pd_tracks['yVelocity']          = pd.NA \n",
    "# pd_tracks['xAcceleration']      = pd.NA \n",
    "# pd_tracks['yAcceleration']      = pd.NA \n",
    "# pd_tracks['frontSightDistance'] = pd.NA \n",
    "# pd_tracks['backSightDistance']  = pd.NA \n",
    "# pd_tracks['dhw']                = pd.NA \n",
    "# pd_tracks['thw']                = pd.NA \n",
    "# pd_tracks['ttc']                = pd.NA \n",
    "\n",
    "# # Nine-box data\n",
    "# # NOTE: initial to -1 indicate invalid value\n",
    "# pd_tracks['precedingXVelocity'] = pd.NA \n",
    "# pd_tracks['precedingId']        = pd.NA \n",
    "# pd_tracks['followingId']        = pd.NA \n",
    "# pd_tracks['leftPrecedingId']    = pd.NA \n",
    "# pd_tracks['leftAlongsideId']    = pd.NA \n",
    "# pd_tracks['leftFollowingId']    = pd.NA \n",
    "# pd_tracks['rightPrecedingId']   = pd.NA \n",
    "# pd_tracks['rightAlongsideId']   = pd.NA \n",
    "# pd_tracks['rightFollowingId']   = pd.NA \n",
    "\n",
    "# pd_tracks['laneId']      = df_obj_augment['lane_id']\n",
    "# pd_tracks['angle']       = df_obj_augment['h']\n",
    "# pd_tracks['orientation'] = pd.NA \n",
    "# pd_tracks['yaw_rate ']   = pd.NA \n",
    "# pd_tracks['ego_offset']  = pd.NA \n",
    "\n",
    "# # Extra columns\n",
    "# pd_tracks['roadID'] = df_obj_augment['road_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct pd_tracks_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trackId</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>initialFrame</th>\n",
       "      <th>finalFrame</th>\n",
       "      <th>numFrames</th>\n",
       "      <th>class</th>\n",
       "      <th>drivingDirection</th>\n",
       "      <th>traveledDistance</th>\n",
       "      <th>minXVelocity</th>\n",
       "      <th>maxXVelocity</th>\n",
       "      <th>meanXVelocity</th>\n",
       "      <th>minDHW</th>\n",
       "      <th>minTHW</th>\n",
       "      <th>minTTC</th>\n",
       "      <th>numLaneChanges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [trackId, length, width, initialFrame, finalFrame, numFrames, class, drivingDirection, traveledDistance, minXVelocity, maxXVelocity, meanXVelocity, minDHW, minTHW, minTTC, numLaneChanges]\n",
       "Index: []"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_tracks_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct pd_recording_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordingId</th>\n",
       "      <th>frameRate</th>\n",
       "      <th>locationId</th>\n",
       "      <th>speedLimit</th>\n",
       "      <th>month</th>\n",
       "      <th>weekDay</th>\n",
       "      <th>startTime</th>\n",
       "      <th>duration</th>\n",
       "      <th>totalDrivenDistance</th>\n",
       "      <th>totalDrivenTime</th>\n",
       "      <th>numVehicles</th>\n",
       "      <th>numCars</th>\n",
       "      <th>numTrucks</th>\n",
       "      <th>numBuses</th>\n",
       "      <th>laneMarkings</th>\n",
       "      <th>scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [recordingId, frameRate, locationId, speedLimit, month, weekDay, startTime, duration, totalDrivenDistance, totalDrivenTime, numVehicles, numCars, numTrucks, numBuses, laneMarkings, scale]\n",
       "Index: []"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd_recording_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tracks' frame, trackId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_tracks = create_tracks(df_obj_augment)\n",
    "\n",
    "df_tracks['laneId'] = df_tracks['lane_id']\n",
    "df_tracks['roadId'] = df_tracks['road_id']\n",
    "\n",
    "# set for 0, not in use\n",
    "df_tracks['frontSightDistance'] = 0\n",
    "df_tracks['backSightDistance'] = 0\n",
    "\n",
    "df_tracks.to_csv('my_tracks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output File Selection\n",
    "\n",
    "## copy from my_tracks to output file pd_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_track_statistics(df_tracks): \n",
    "    \"\"\"\n",
    "    Calculates track statistics for each vehicle ID in the DataFrame.\n",
    "\n",
    "    Args:\n",
    "      df_tracks: DataFrame containing track information with columns:\n",
    "                 'frame', 'trackId', 'x', 'y', 'XVelocity', 'dhw', 'thw', 'ttc', 'lane_id'\n",
    "\n",
    "    Returns:\n",
    "      A new DataFrame containing track statistics for each vehicle ID.\n",
    "    \"\"\"\n",
    "\n",
    "    track_stats = []\n",
    "    for track_id, group in df_tracks.groupby('trackId'):\n",
    "        first_row = group.iloc[0] \n",
    "        # Get initial and final frame\n",
    "        initial_frame = group['frame'].min()\n",
    "        final_frame = group['frame'].max()\n",
    "\n",
    "        # Calculate the differences between consecutive points\n",
    "        group['x_diff'] = group['xCenter'].diff()\n",
    "        group['y_diff'] = group['yCenter'].diff()\n",
    "        group['x_diff'] = group['x_diff'].fillna(0)\n",
    "        group['y_diff'] = group['y_diff'].fillna(0)\n",
    "        group['distance'] = np.sqrt(group['x_diff']**2 + group['y_diff']**2)\n",
    "        total_distance = group['distance'].sum()\n",
    "\n",
    "\n",
    "        # Calculate the Euclidean distance for each consecutive pair\n",
    "        # TODO\n",
    "        # group['distance'] = np.sqrt(group['x_diff']**2 + group['y_diff']**2)\n",
    "\n",
    "        # Sum the distances to get the total traveled distance\n",
    "        # total_distance = group['distance'].sum()\n",
    "\n",
    "        # Calculate velocity statistics\n",
    "        min_x_velocity = group['xVelocity'].min()\n",
    "        max_x_velocity = group['xVelocity'].max()\n",
    "        mean_x_velocity = group['xVelocity'].mean()\n",
    "\n",
    "        # Calculate minimum values for DHW, THW, and TTC\n",
    "        min_dhw = group['dhw'].min()\n",
    "        min_thw = group['thw'].min()\n",
    "        min_ttc = group['ttc'].min()\n",
    "\n",
    "        # Count lane changes within same 'road_id' (simple approach)\n",
    "        num_lane_changes = 0\n",
    "        for _, road_group in group.groupby('roadId'):\n",
    "          curr_lane_diff = road_group['laneId'].diff().dropna()\n",
    "          num_lane_changes += (curr_lane_diff != 0).sum()\n",
    "\n",
    "        # Create a dictionary for track statistics\n",
    "        track_stats.append({\n",
    "            'id': track_id,\n",
    "            'vehicle_id': first_row['obj_id'],\n",
    "            'width': first_row['width'],\n",
    "            'height': first_row['length'],\n",
    "            'initialFrame': initial_frame,\n",
    "            'finalFrame': final_frame,\n",
    "            'numFrames': len(group),\n",
    "            'class': first_row['class_str'],\n",
    "            'drivingDirection': 2 if first_row['laneId'] >= 0 else 1,\n",
    "            'traveledDistance': total_distance,\n",
    "            'minXVelocity': min_x_velocity,\n",
    "            'maxXVelocity': max_x_velocity,\n",
    "            'meanXVelocity': mean_x_velocity,\n",
    "            'minDHW': min_dhw,\n",
    "            'minTHW': min_thw,\n",
    "            'minTTC': min_ttc,\n",
    "            'numLaneChanges': num_lane_changes\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(track_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_tracks_meta = ['trackId', 'length', 'width', 'initialFrame', 'finalFrame', 'numFrames',\n",
    "       'class', 'drivingDirection', 'traveledDistance', 'minXVelocity',\n",
    "       'maxXVelocity', 'meanXVelocity', 'minDHW', 'minTHW', 'minTTC',\n",
    "       'numLaneChanges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tracks = df_tracks.loc[:, columns_tracks].copy()\n",
    "pd_tracks['class_str'] = df_tracks['class_str'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute track_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g7/hfvhwzs95vg_zscbgk3pr0740000gn/T/ipykernel_11566/278284213.py:23: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  group['x_diff'] = group['x_diff'].fillna(0)\n",
      "/var/folders/g7/hfvhwzs95vg_zscbgk3pr0740000gn/T/ipykernel_11566/278284213.py:24: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  group['y_diff'] = group['y_diff'].fillna(0)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'obj_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.15/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'obj_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pd_tracks_meta \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_track_statistics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpd_tracks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# drop class_str for meta computation purpose\u001b[39;00m\n\u001b[1;32m      4\u001b[0m pd_tracks\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_str\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[125], line 55\u001b[0m, in \u001b[0;36mcalculate_track_statistics\u001b[0;34m(df_tracks)\u001b[0m\n\u001b[1;32m     50\u001b[0m       num_lane_changes \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (curr_lane_diff \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# Create a dictionary for track statistics\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     track_stats\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: track_id,\n\u001b[0;32m---> 55\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvehicle_id\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mfirst_row\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mobj_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m: first_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheight\u001b[39m\u001b[38;5;124m'\u001b[39m: first_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minitialFrame\u001b[39m\u001b[38;5;124m'\u001b[39m: initial_frame,\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinalFrame\u001b[39m\u001b[38;5;124m'\u001b[39m: final_frame,\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumFrames\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(group),\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m: first_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_str\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrivingDirection\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlaneId\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraveledDistance\u001b[39m\u001b[38;5;124m'\u001b[39m: total_distance,\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminXVelocity\u001b[39m\u001b[38;5;124m'\u001b[39m: min_x_velocity,\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxXVelocity\u001b[39m\u001b[38;5;124m'\u001b[39m: max_x_velocity,\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeanXVelocity\u001b[39m\u001b[38;5;124m'\u001b[39m: mean_x_velocity,\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminDHW\u001b[39m\u001b[38;5;124m'\u001b[39m: min_dhw,\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminTHW\u001b[39m\u001b[38;5;124m'\u001b[39m: min_thw,\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminTTC\u001b[39m\u001b[38;5;124m'\u001b[39m: min_ttc,\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumLaneChanges\u001b[39m\u001b[38;5;124m'\u001b[39m: num_lane_changes\n\u001b[1;32m     71\u001b[0m     })\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(track_stats)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.15/lib/python3.10/site-packages/pandas/core/series.py:1112\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.15/lib/python3.10/site-packages/pandas/core/series.py:1228\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1228\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.15/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'obj_id'"
     ]
    }
   ],
   "source": [
    "pd_tracks_meta = calculate_track_statistics(pd_tracks)\n",
    "\n",
    "# drop class_str for meta computation purpose\n",
    "pd_tracks.drop('class_str', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store All three outputs to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tracks.to_csv('tracks_result.csv', index=False)\n",
    "pd_tracks_meta.to_csv('tracks_meta_result.csv', index=False)\n",
    "pd_recording_meta.to_csv('recording_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame                         0\n",
      "trackId                       1\n",
      "obj_id                        1\n",
      "xCenter                0.027298\n",
      "yCenter               -0.001449\n",
      "length                      0.0\n",
      "width                       0.0\n",
      "xVelocity             15.805735\n",
      "yVelocity             -0.841602\n",
      "xAcceleration         -1.755706\n",
      "yAcceleration         -0.132465\n",
      "frontSightDistance            0\n",
      "backSightDistance             0\n",
      "dhw                           0\n",
      "thw                           0\n",
      "ttc                         0.0\n",
      "precedingXVelocity            0\n",
      "precedingId                   0\n",
      "followingId              403803\n",
      "leftPrecedingId          386711\n",
      "leftAlongsideId          403803\n",
      "leftFollowingId          403803\n",
      "rightPrecedingId         398015\n",
      "rightAlongsideId         398015\n",
      "rightFollowingId         403803\n",
      "roadId                      1.0\n",
      "laneId                      1.0\n",
      "angle                         0\n",
      "orientation           -0.053196\n",
      "yaw_rate              -0.008381\n",
      "ego_offset                    0\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(pd_tracks.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
